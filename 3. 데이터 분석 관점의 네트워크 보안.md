# 데이터분석 관점의 네트워크 보안

#### 웹 해킹 주요 타겟 => 파일, 변수  
URL : 경로, 파일  
URI : URL + 변수=값   
1. 웹 페이지 파일에 웹서버에 보여지는 정보와 보여지면 안되는 정보 있는데 해커들은 보여지면 안되는 부분 해킹 시도    
2. 변수 값에 따라 사용자에게 보여지는 정보가 달라짐 -> 변수값 해킹하면 보여지면 안되는 정보 볼 수 있음  

#### IDS - 패턴 매칭  
공격 패턴이면 차단, 아니면 통과  

#### 네트워크 보안 관점에 서 패턴 매칭 문제점  
```
타겟이 아닌 다른 정보가 섞이면 분류해야하므로 어려워짐!  
반드시 타겟만의 정보만을 수집해야 한다는 특징이 있음!  
그러나 네트워크 특징이 피하식별이 안됨! -> 타겟을 대상으로 트래픽 수집 불가, 부정확한 정보 굉장히 많음  
```

## 엘라스틱 서치 localhost 변경  
```
C:\elk\elasticsearch-7.8.0-windows-x86_64\elasticsearch-7.8.0\config

> elasticsearch.yml에서 Network 부분 network.host: 10.100.244.12(내 ip 주소)   
> Discovery 부분 cluster.initial_master_nodes: ["10.100.244.12"]   

C:\elk\kibana-7.8.0-windows-x86_64\kibana-7.8.0-windows-x86_64\config
> 7번 line ->  server.host: "10.100.244.12"  

# The URLs of the Elasticsearch instances to use for all your queries.
elasticsearch.hosts: ["http://10.100.244.12:9200"]
```

```
키바나에서 ML에 csv 파일 업로드  
override settings에서 필드 이름 세팅 변경할 수 있음!!!  
````

#### logstash  
```
C:\elk\logstash-7.8.0\logstash-7.8.0\config -> logstash.yml  
86번째 줄 : config.reload.automatic: true

> pipeline.yml  => 파이프 라인 여러개 쓰고 싶을 때 참고!!!!
- pipeline.id: test1
  pipeline.workers: 1     //코어 개수
  path.config : "/tmp/logstash/1.conf"
  
- pipeline.id: test2
  pipeline.workers: 3    //코어 개수
  path.config : "/tmp/logstash/2conf"
```

#### elk 폴더 안에 test.conf 파일 만들기!  
```
input {
	file {
		path => "c:/elk/log/apache.log"
		start_position => "beginning"
		sincedb_path => "nul"
	}
}

filter {
	dissect {
		mapping => {
			"message" => '%{clientip} %{} %{} [%{timestamp}] "%{method} %{uri} %{}" %{status} %{bytes}'
		}
	}
	

	if "?" in [uri] {
		dissect {
			mapping => {"uri" => "%{url}?%{var}" }
			remove_field => "uri"
		}
	} else {
		mutate {
			rename => {"uri" => "url"}
		}
	}

	if "." in [url] {
		grok {
			match => {
				"url" => ".*\/(?<file>.*)"
			}
		}
		grok {
			match => {
				"file" => ".*\.(?<ext>.*)"
			}
		}
	}

	mutate {	//지우는 옵션!!!  
		strip => "bytes"
	}

	if [var] {
		ruby {
			code => 'event.set("var_len", event.get("var").length)'
		}
	}

	date {
		match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
		target => "@timestamp"
		remove_field => ["timestamp", "@version", "path", "host", "message"]
	}
}

output {
	#stdout {}
	elasticsearch {
		hosts => "10.100.244.12"
		index => "apache-%{+yyyy}"
	}
}
```
#### cmd
> 위 소스에서 filter 부분 내용 지우고 output 부분에서 stdout()만 남기고 지운 상태  
```
C:\elk\logstash-7.8.0\logstash-7.8.0\bin>logstash -f c:\elk\test.conf
```
-----

#### 플러그인 옵션 지정방법  
```
plugin{
  1. 제목 => "단일값"
  2. 제목 => [ "값1", "값2"]
  3. 제목 => {
  	"대상" => "특정 동작"
	
  	}
}
```
#### 키바나 -> stack management -> Index Pattern  

#### 키바나에서 표 만드는 법  
키바나 -> Visualize 메뉴  

문자열은 count랑 Unique count밖에 선택 못 함  
나머지는 전부 숫자 metric에 대해서만 적용 가능  
=> 데이터룰 숫자로 바꿔야 다양한 옵션 선택 가능  

> Buckets: 어떤 단위로 데이터 선택할지

#### 키바나 -> devtools -> Grok Debugger  
