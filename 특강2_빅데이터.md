https://books.google.com/ngrams  
```
구글이 책을 스캔해서 단어단위로 저장하고 있음, 전체 모집단에서 'Korea'라는 단어의 출현 빈도 볼 수 있음  
-> 책이 디지털화 되어 있기 때문에 가능!!  
-> 마케팅적으로 네이버스토어팜에서 단어 빈도가 많아졌는데 상품이 별로 없으면 상품 개발함 => 인사이트 얻음  
-> 기존에 있던 아날로그 데이터가 디지털로 많이 바뀌었음  
```
<br>

https://trends.google.com/trends/?geo=US  
```
트렌드 데이터 알 수 있음  
데이터 활용하고 싶으면 다운로드 누르면 csv 파일로 바로 다운로드 가능  
```
<br>

https://datalab.naver.com/keyword/trendSearch.naver  
```
네이버 트렌드   
검색량 볼 수 있음     
```

분석할 일 있으면 연속 데이터 먼저 분석하기(ex. 미세먼지 추이)   
Tableau  

```
1. 통계 자료 볼 때 * 있는거 먼저 보기! 통계적으로 유의하다는 뜻  
2. + : 양의 영향, -: 음의 영향    
```

빅데이터 시대 전수 조사 왜 안했는지 피드백 하는 경우 많아짐!!  
이미지 데이터는 전체 데이터 분석하려면 용량 많이 들어서 sampling 하는거 어쩔 수 없음  

데이터에서 평균과 표준편차가 가장 중요!!   

분석에서 RMSE 중요  

#### KNN 공간 순환 신경망  
```
KNN 알고리즘을 이용하여 연구자가 지정한 K개의 유클리드 거리 기준 근접 관측소를 알고리즘으로 찾아 PM10 데이터를 추가하여 순환 신경망 분석을 시행하여 시공간 정보를 고려하게 함.  
데이터 정제해서 넣으면 결과 더 좋아지는데 아직까지는 한계가 있음   
RMSE = 8.0 정도로 좋아짐 => ICNN 사용했더니 RMSE = 2 수준으로 훨씬 예측 정확해짐   
```
<br>
<br>

https://www.autodraw.com/       //그림 자동으로그려주는 사이트  
https://quickdraw.withgoogle.com/      //내가 그린 그림 맞히는 AI  

---


#### 빅데이터 분석 개요
- 관련 기술 발전 + 데이터 생성량 증가 => 빅데이터 환경 조성   
- 데이터 분석은 Data를 정보, 지식, 지혜화 하는 과정

유니티에서 머신러닝 지원

<br>
<br>

#### 기초 통계
통계분석에는 두 분야가 있음 : 1. 기술통계 2. 추측통계   
   
기술통계: 집단에 관한 여러 특성을 수량화하여 객관적인 데이터로 나타내는 통계 분석 방법론  
  ex. **평균**, 중앙값, 산포도, 분산, **표준편차, 왜도, 첨도** -> 평균, 표준편차 정보 짱많당
  분석하기 전에 기술통계표 먼저 나열하면 도움 됨 -> 보통 데이터 개수, 평균, 표준편차, 최댓값, 최솟값 reporting 함  
  

### R 실습
#### R 기초
```
rm(list = lS())   //첫 줄에 메모리 정리 코드 써주는 거 추천

a<-1
if (a > 0){
  print('a > 0')
}

print('a')
cat('a', 'b')     //print인데 인자 2개 이상 가능, 개행 안됨  

#함수 만들기
y<-function(a){
  return(a*3)
}
y(10)


i <- 1
while(i<10){
  print(i)
  i <- i + 1
}

#  * 출력
for(i in 1:5){
  for(j in 1:i){
    cat('*')
  }
  cat('\n')
}

#matrix 만들기
> a <- matrix(1:100, 10,10)
> a        //전체 출력
> a[1,1]   //indexing
  1
> a[1,]    //1번 열 선택
 [1]  1 11 21 31 41 51 61 71 81 91

> a[1:5, 4]       //범위로 선택: 슬라이싱
[1] 31 32 33 34 35 
```
<br>

#### R dataframe 실습
```
> a <- as.data.frame(a)      //data type 데이터 프레임으로 바꾸기
> class(a)        // 데이터 타입 확인 가능
>str(a)        //데이터 구조 알 수 있음


iris          //R에서 제공해주는 데이터
df <- iris
str(df)     
plot(df)    //데이터 시각화, 그래프 그려줌, 탐색적으로 볼 때 좋음

```

http://www.kocw.net/home/search/search.do     //이동현 강사님이 찍으신 빅데이터 강의(R) 있음
  
    
추측 통계 : 수집된 자료를 이용해 모집단에 대한 의사 결정을 하는 것  
   - 모수 추정: 모집단의 평균, 분산 등 추정
   - 가설 검정: 회귀 분석 통해서도 가설 검정 할 수 있음  
   - 예측: 데이터 분석의 분야 중 하나  
  
#### 탐색적 자료 분석(EDA)
데이터를 가지고 뭘 할 수 있는지 살펴보는 것    

<br>

### 회귀분석
####  R을 통한 회귀분석
a<-lm(종속변수~독립변수1+독립변수2+...+독립변수n)
summary(a)

```
rm(list =ls())

df<-iris
str(df)
model <- lm(Sepal.Length ~ Sepal.Width + Petal.Length
            + Petal.Width, data = df)

summary(model)
```

<br>
다중공선성: 독립변수들 간의 상관계수가 높을 때 회귀 계수 추정에 영향을 주는 것
다중공선성 발생 -> 해결법 : VIF(엄밀하게는 5이상)인 변수 등 상관관계에 강하게 영향을 주는 변수 제거

```
install.packages('car')             
library(car)
vif(model)     //다중공선성 검증하는 지표
cor.test(df$Sepal.Length, df$Sepal.Width)    //통계적 유의미성 알 수 있음
plot(df)                                     //산점도 확인
plot(df$Petal.Length, df$Petal.Width)     //변수 선택해서 산점도 볼 수 있음

```



